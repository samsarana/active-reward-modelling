\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Background}{4}{part.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{5}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Relation to Material Studied on the MSc Course}{5}{section.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Neural Networks}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{Sutton2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Reinforcement Learning}{7}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Elements of Reinforcement Learning}{7}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Finite Markov Decision Processes}{7}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}The Agent-Environment Interface}{8}{subsection.3.2.1}\protected@file@percent }
\newlabel{subsection:agent_env_interface}{{3.2.1}{8}{The Agent-Environment Interface}{subsection.3.2.1}{}}
\citation{Sutton2018}
\citation{Amodei2016}
\citation{Sutton2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Goals and Rewards}{9}{subsection.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Returns and Episodes}{9}{subsection.3.2.3}\protected@file@percent }
\newlabel{rets_and_episodes}{{3.2.3}{9}{Returns and Episodes}{subsection.3.2.3}{}}
\citation{Sutton2018}
\newlabel{G_t}{{3.1}{10}{(Future discounted) return}{equation.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Policies and Value Functions}{10}{subsection.3.2.4}\protected@file@percent }
\newlabel{policy_value_functions}{{3.2.4}{10}{Policies and Value Functions}{subsection.3.2.4}{}}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\newlabel{v_pi}{{3.2}{11}{State-value function}{equation.3.2.2}{}}
\newlabel{v_pi}{{3.3}{11}{Action-value function}{equation.3.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Optimal Policies and Optimal Value Functions}{11}{subsection.3.2.5}\protected@file@percent }
\newlabel{optimal_policy_value_functions}{{3.2.5}{11}{Optimal Policies and Optimal Value Functions}{subsection.3.2.5}{}}
\newlabel{Q_claim}{{1}{11}{}{claim.1}{}}
\citation{Sutton2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}Bellman Equations}{12}{subsection.3.2.6}\protected@file@percent }
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Achiam2019}
\newlabel{bellman_q*}{{4}{13}{Bellman equation for $ q_* $ {\cite [p.~63]{Sutton2018}}}{proposition.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Reinforcement Learning Solution Methods}{13}{section.3.3}\protected@file@percent }
\newlabel{RL_solution_methods}{{3.3}{13}{Reinforcement Learning Solution Methods}{section.3.3}{}}
\citation{Mnih2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Taxonomy of RL Solution Methods}{14}{subsection.3.3.1}\protected@file@percent }
\newlabel{subsection:rl_taxonomy}{{3.3.1}{14}{Taxonomy of RL Solution Methods}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Deep Q-network}{14}{subsection.3.3.2}\protected@file@percent }
\newlabel{DQN}{{3.3.2}{14}{Deep Q-network}{subsection.3.3.2}{}}
\citation{Christiano2017}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Deep Q-learning with experience replay.\relax }}{16}{algorithm.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:dqn}{{1}{16}{Deep Q-learning with experience replay.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Reinforcement Learning from Unknown Reward Functions}{16}{section.3.4}\protected@file@percent }
\citation{Ng2000}
\citation{Ziebart2008}
\citation{Ho2016}
\citation{Hester2017}
\citation{Knox2009}
\citation{Warnell2017}
\citation{Wilson2012}
\citation{Christiano2017}
\citation{Ibarz2018}
\gdef \LT@i {\LT@entry 
    {1}{99.88464pt}\LT@entry 
    {1}{99.48465pt}\LT@entry 
    {1}{99.48465pt}\LT@entry 
    {1}{99.48465pt}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Summary of the properties of using different forms of human feedback in RL without a reward function.\relax }}{17}{table.3.1}\protected@file@percent }
\newlabel{table:1}{{3.1}{17}{Summary of the properties of using different forms of human feedback in RL without a reward function.\relax }{table.3.1}{}}
\newlabel{footnote:exploration}{{3}{17}{}{Hfootnote.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Reward Learning from Trajectory Preferences with Handcrafted Feature Transformations}{18}{subsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Active Preference-Based Learning of Reward Functions}{18}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Active Preference-Based Learning of Reward Functions}{18}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{DemPref}{18}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Reward Learning from Trajectory Preferences in Deep RL}{18}{subsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Setting}{18}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Method}{18}{section*.6}\protected@file@percent }
\citation{Christiano2017}
\citation{Ho2016}
\citation{Mnih2016}
\citation{Schulman2015}
\citation{Ibarz2018}
\citation{Christiano2017}
\citation{Ibarz2018}
\citation{Hester2017}
\citation{Ibarz2018}
\citation{Christiano2017}
\@writefile{toc}{\contentsline {subsubsection}{Process 1: Training the policy}{19}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Process 2: Selecting and annotating clip pairs}{20}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Process 3: Training the reward model}{20}{section*.9}\protected@file@percent }
\newlabel{assumption:1}{{1}{20}{}{assumption.1}{}}
\newlabel{eq:1}{{3.8}{20}{Process 3: Training the reward model}{equation.3.4.8}{}}
\citation{elo1978rating}
\citation{Gal2017a}
\citation{Gal2017a}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Uncertainty in Deep Learning}{22}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Bayesian Neural Networks}{23}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Model Uncertainty in BNNs}{23}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Active Learning}{24}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Acquisition Functions}{24}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Max Entropy}{24}{subsection.5.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}Variation Ratios}{24}{subsection.5.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.3}Mean STD}{24}{subsection.5.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.4}BALD}{24}{subsection.5.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Applying Active Learning to RL without a reward function}{24}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}APRIL}{25}{subsection.5.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Active Preference-Based Learning of Reward Functions with handcrafted feature transformations}{25}{subsection.5.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Active Preference-Based Learning of Reward Functions}{25}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Active Preference-Based Learning of Reward Functions}{25}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{DemPref}{25}{section*.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Deep RL from Human Preferences}{25}{subsection.5.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Innovation}{26}{part.2}\protected@file@percent }
\citation{Christiano2017}
\citation{Christiano2017}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Method}{27}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Possible failure modes of active reward modelling}{27}{section.6.1}\protected@file@percent }
\citation{Gal2017b}
\citation{Kirsch2019}
\citation{cohen2017emnist}
\citation{Christiano2017}
\citation{van1995python}
\citation{paszke2017automatic}
\citation{jones2001}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Applying acquisition functions to reward modelling}{28}{section.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}ARMA}{28}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Acquisition Functions}{28}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Uncertainty Estimates}{28}{section.6.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Implementation Details}{28}{section.6.6}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces ARMA: Active Reward Modelling for Agent Alignment.\relax }}{29}{algorithm.2}\protected@file@percent }
\newlabel{alg:arma}{{2}{29}{ARMA: Active Reward Modelling for Agent Alignment.\relax }{algorithm.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Experimental Details}{30}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}CartPole-v0}{30}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Results}{31}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}CartPole-v0}{31}{section.8.1}\protected@file@percent }
\bibstyle{apalike}
\bibdata{library,additional}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Conclusions}{32}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Summary}{32}{section.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Evaluation}{32}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Future Work}{32}{section.9.3}\protected@file@percent }
\bibcite{Achiam2019}{Achiam, 2019}
\bibcite{Amodei2016}{Amodei et\nobreakspace  {}al., 2016}
\bibcite{Christiano2017}{Christiano et\nobreakspace  {}al., 2017}
\bibcite{cohen2017emnist}{Cohen et\nobreakspace  {}al., 2017}
\bibcite{elo1978rating}{Elo, 1978}
\bibcite{Gal2017a}{Gal, 2017}
\bibcite{Gal2017b}{Gal et\nobreakspace  {}al., 2017}
\bibcite{Hester2017}{Hester et\nobreakspace  {}al., 2017}
\bibcite{Ho2016}{Ho and Ermon, 2016}
\bibcite{Ibarz2018}{Ibarz et\nobreakspace  {}al., 2018}
\@writefile{toc}{\contentsline {chapter}{References}{33}{chapter*.13}\protected@file@percent }
\bibcite{jones2001}{Jones et\nobreakspace  {}al., 01 }
\bibcite{Kirsch2019}{Kirsch et\nobreakspace  {}al., 2019}
\bibcite{Knox2009}{Knox and Stone, 2009}
\bibcite{Mnih2016}{Mnih et\nobreakspace  {}al., 2016}
\bibcite{Mnih2015}{Mnih et\nobreakspace  {}al., 2015}
\bibcite{Ng2000}{Ng and Russell, 2000}
\bibcite{paszke2017automatic}{Paszke et\nobreakspace  {}al., 2017}
\bibcite{Schulman2015}{Schulman et\nobreakspace  {}al., 2015}
\bibcite{Sutton2018}{Sutton and Barto, 2018}
\bibcite{van1995python}{Van\nobreakspace  {}Rossum and Drake\nobreakspace  {}Jr, 1995}
\bibcite{Warnell2017}{Warnell et\nobreakspace  {}al., 2017}
\bibcite{Wilson2012}{Wilson et\nobreakspace  {}al., 2012}
\bibcite{Ziebart2008}{Ziebart et\nobreakspace  {}al., 2008}
\@writefile{toc}{\contentsline {chapter}{Appendices}{}{section*.14}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Some Appendix Material}{37}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
