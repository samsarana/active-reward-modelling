\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{4}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Relation to Material Studied on the MSc Course}{4}{section.1.1}\protected@file@percent }
\citation{Sutton2018}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Reinforcement Learning}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Elements of Reinforcement Learning}{5}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Finite Markov Decision Processes}{5}{section.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}The Agent-Environment Interface}{6}{subsection.2.2.1}\protected@file@percent }
\citation{Sutton2018}
\citation{Amodei2016}
\citation{Sutton2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Goals and Rewards}{7}{subsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Returns and Episodes}{7}{subsection.2.2.3}\protected@file@percent }
\newlabel{rets_and_episodes}{{2.2.3}{7}{Returns and Episodes}{subsection.2.2.3}{}}
\citation{Sutton2018}
\newlabel{G_t}{{2.1}{8}{(Future discounted) return}{equation.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Policies and Value Functions}{8}{subsection.2.2.4}\protected@file@percent }
\newlabel{policy_value_functions}{{2.2.4}{8}{Policies and Value Functions}{subsection.2.2.4}{}}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\newlabel{v_pi}{{2.2}{9}{State-value function}{equation.2.2.2}{}}
\newlabel{v_pi}{{2.3}{9}{Action-value function}{equation.2.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Optimal Policies and Optimal Value Functions}{9}{subsection.2.2.5}\protected@file@percent }
\newlabel{optimal_policy_value_functions}{{2.2.5}{9}{Optimal Policies and Optimal Value Functions}{subsection.2.2.5}{}}
\newlabel{Q_claim}{{1}{9}{}{claim.1}{}}
\citation{Sutton2018}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Bellman Equations}{10}{subsection.2.2.6}\protected@file@percent }
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Sutton2018}
\citation{Achiam2019}
\newlabel{bellman_q*}{{4}{11}{Bellman equation for $ q_* $ {\cite [p.~63]{Sutton2018}}}{proposition.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Reinforcement Learning Solution Methods}{11}{section.2.3}\protected@file@percent }
\newlabel{RL_solution_methods}{{2.3}{11}{Reinforcement Learning Solution Methods}{section.2.3}{}}
\citation{Mnih2015}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Taxonomy of RL Solution Methods}{12}{subsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Deep Q-network}{12}{subsection.2.3.2}\protected@file@percent }
\newlabel{DQN}{{2.3.2}{12}{Deep Q-network}{subsection.2.3.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Deep Q-learning with experience replay.\relax }}{14}{algorithm.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:dqn}{{1}{14}{Deep Q-learning with experience replay.\relax }{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Reinforcement Learning from Unknown Reward Functions}{14}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Reward Learning with Handcrafted Feature Transformations}{15}{subsection.2.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Active Preference-Based Learning of Reward Functions}{15}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Active Preference-Based Learning of Reward Functions}{15}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{DemPref}{15}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Reward Learning in Deep RL}{15}{subsection.2.4.2}\protected@file@percent }
\citation{Gal2017a}
\citation{Gal2017a}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Uncertainty in Deep Learning}{16}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Bayesian Neural Networks}{17}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Model Uncertainty in BNNs}{17}{section.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Active Learning}{18}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Acquisition Functions}{18}{section.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Max Entropy}{18}{subsection.4.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Variation Ratios}{18}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.3}Mean STD}{18}{subsection.4.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.4}BALD}{18}{subsection.4.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Applying Active Learning to RL without a reward function}{18}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}APRIL}{19}{subsection.4.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Active Preference-Based Learning of Reward Functions with handcrafted feature transformations}{19}{subsection.4.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Active Preference-Based Learning of Reward Functions}{19}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Batch Active Preference-Based Learning of Reward Functions}{19}{section*.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{DemPref}{19}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}Deep RL from Human Preferences}{19}{subsection.4.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Method}{20}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Training Protocol}{20}{section.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Acquisition Functions}{20}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Uncertainty Estimates}{20}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Implementation Details}{20}{section.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Experimental Details}{21}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}CartPole-v0}{21}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Results}{22}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}CartPole-v0}{22}{section.7.1}\protected@file@percent }
\bibstyle{plain}
\bibdata{MSc}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Conclusions}{23}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Summary}{23}{section.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Evaluation}{23}{section.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Future Work}{23}{section.8.3}\protected@file@percent }
\bibcite{Achiam2019}{1}
\bibcite{Amodei2016}{2}
\bibcite{Gal2017a}{3}
\bibcite{Mnih2015}{4}
\bibcite{Sutton2018}{5}
\@writefile{toc}{\contentsline {chapter}{References}{24}{chapter*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Appendices}{}{section*.9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Some Appendix Material}{26}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
